% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nestedCV.R
\name{regular_nestedCV}
\alias{regular_nestedCV}
\title{Regular nested cross validation for feature selection and parameter tuning}
\usage{
regular_nestedCV(train.ds = NULL, validation.ds = NULL,
  label = "class", method.model = "classification",
  is.simulated = TRUE, ncv_folds = c(10, 10), param.tune = FALSE,
  learning_method = "rf", xgb.obj = "binary:logistic",
  importance.algorithm = "ReliefFequalK",
  relief.k.method = "k_half_sigma", num_tree = 500, verbose = FALSE)
}
\arguments{
\item{train.ds}{A training data frame with last column as outcome}

\item{validation.ds}{A validation data frame with last column as outcome}

\item{label}{A character vector of the outcome variable column name.}

\item{method.model}{Column name of outcome variable (string), classification or regression. If the analysis goal is classification make the column a factor type. 
For regression, make outcome column numeric type.}

\item{is.simulated}{A TRUE or FALSE character for data type}

\item{ncv_folds}{A numeric vector to indicate nested cv folds: c(k_outer, k_inner)}

\item{param.tune}{A TRUE or FALSE character for tuning parameters}

\item{learning_method}{Name of the method: glmnet/xgbTree/rf}

\item{xgb.obj}{Name of xgboost algorithm}

\item{importance.algorithm}{A character vestor containing a specific importance algorithm subtype}

\item{relief.k.method}{A character of numeric to indicate number of nearest neighbors for relief algorithm.
Possible characters are: k_half_sigma (floor((num.samp-1)*0.154)), m6 (floor(num.samp/6)), 
myopic (floor((num.samp-1)/2)), and m4 (floor(num.samp/4))}

\item{num_tree}{Number of trees in random forest and xgboost methods}

\item{verbose}{A flag indicating whether verbose output be sent to stdout}
}
\value{
A list with:
\describe{
  \item{Train}{Training data accuracy}
  \item{Validation}{Validation data accuracy}
  \item{Features}{number of variables detected correctly in nested cross validation}
  \item{Elapsed}{total elapsed time}
} 
num.samples <- 100
num.variables <- 100
pct.signals <- 0.1
label <- "class"
sim.data <- createSimulation(num.samples = num.samples,
                             num.variables = num.variables,
                             pct.signals = pct.signals,
                             sim.type = "mainEffect",
                             label = label,
                             verbose = FALSE)                         
rnCV.results <- regular_nestedCV(train.ds = sim.data$train, 
                                 validation.ds = sim.data$holdout, 
                                 label = label,
                                 is.simulated = TRUE,
                                 ncv_folds = c(10, 10),
                                 param.tune = FALSE,
                                 learning_method = "rf",
                                 importance.algorithm = "ReliefFbestK",
                                 num_tree = 500, 
                                 verbose = FALSE)
}
\description{
Regular nested cross validation for feature selection and parameter tuning
}
\seealso{
Other nestedCV: \code{\link{consensus_nestedCV}}
}
\concept{nestedCV}
